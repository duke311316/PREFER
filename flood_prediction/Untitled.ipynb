{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eaa86a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe is being concatenated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 18:11:19.325053: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 3s 12ms/step - loss: 0.7678 - val_loss: 0.2319\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0219 - val_loss: 0.2059\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0162 - val_loss: 0.2079\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.2116\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0137 - val_loss: 0.2020\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.2014\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0114 - val_loss: 0.1993\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0113 - val_loss: 0.1895\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0118 - val_loss: 0.1814\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0101 - val_loss: 0.1801\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0094 - val_loss: 0.1737\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0099 - val_loss: 0.1734\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.1643\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0100 - val_loss: 0.1631\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.1517\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.1550\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0101 - val_loss: 0.1449\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.1347\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.1341\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.1266\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.1381\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.1171\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0078 - val_loss: 0.1158\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0077 - val_loss: 0.1090\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.1099\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.0102 - val_loss: 0.1056\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0078 - val_loss: 0.1051\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.0971\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.0083 - val_loss: 0.1044\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0080 - val_loss: 0.0932\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.1006\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.1151\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.1008\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.0949\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0071 - val_loss: 0.1152\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0106 - val_loss: 0.1022\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0082 - val_loss: 0.0934\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0086 - val_loss: 0.1069\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0101 - val_loss: 0.0805\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0079 - val_loss: 0.1149\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0079 - val_loss: 0.1000\n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.0797\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.1100\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0081 - val_loss: 0.0923\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0058 - val_loss: 0.0924\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.1054\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0083 - val_loss: 0.0968\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.1109\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0084 - val_loss: 0.1129\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0074 - val_loss: 0.0884\n",
      "209/209 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n",
      "188/188 [==============================] - 3s 11ms/step - loss: 0.9481 - val_loss: 0.1954\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0232 - val_loss: 0.1510\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0167 - val_loss: 0.1502\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0145 - val_loss: 0.1474\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0133 - val_loss: 0.1491\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0124 - val_loss: 0.1418\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0116 - val_loss: 0.1464\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0115 - val_loss: 0.1522\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0112 - val_loss: 0.1555\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0114 - val_loss: 0.1503\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0107 - val_loss: 0.1439\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0111 - val_loss: 0.1508\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0101 - val_loss: 0.1464\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0105 - val_loss: 0.1447\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0100 - val_loss: 0.1493\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.1435\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.1444\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0089 - val_loss: 0.1361\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0093 - val_loss: 0.1570\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0103 - val_loss: 0.1560\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0092 - val_loss: 0.1469\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0090 - val_loss: 0.1363\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.1408\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0084 - val_loss: 0.1446\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.1465\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.1419\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0091 - val_loss: 0.1351\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0072 - val_loss: 0.1319\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.1273\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0085 - val_loss: 0.1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0079 - val_loss: 0.1253\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0069 - val_loss: 0.1200\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0088 - val_loss: 0.1231\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0073 - val_loss: 0.1205\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0083 - val_loss: 0.1229\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0066 - val_loss: 0.1144\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.1142\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0058 - val_loss: 0.1158\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0059 - val_loss: 0.1181\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0059 - val_loss: 0.1126\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0061 - val_loss: 0.1187\n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0060 - val_loss: 0.1194\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0047 - val_loss: 0.1115\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.0055 - val_loss: 0.1104\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0063 - val_loss: 0.1226\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0067 - val_loss: 0.1149\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0041 - val_loss: 0.0984\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0062 - val_loss: 0.1033\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0048 - val_loss: 0.1086\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.0050 - val_loss: 0.0956\n",
      "209/209 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt;\n",
    "import logging;\n",
    "import os;\n",
    "import time;\n",
    "from datetime import date, datetime;\n",
    "from flood_pred_data_processing_V1 import DataProcessor;\n",
    "from flood_pred_models_V1 import FloodModel;\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "Processor = DataProcessor() \n",
    "surrey_df = Processor.process_surrey()\n",
    "# print(surrey_df)\n",
    "wu_df = Processor.concat_multiple_wu_stations()\n",
    "# print (wu_df)\n",
    "\n",
    "Model = FloodModel()  \n",
    "model_df = Processor.build_model_matrix() \n",
    "# model_df.describe().transpose()[['mean', 'std']]\n",
    "\n",
    "features_df = model_df.drop(columns=['water_level'])\n",
    "# Normalize the data\n",
    "normalizer = Model.model_data_normalizer(features_df)\n",
    "normalized_features = normalizer(features_df.to_numpy())\n",
    "\n",
    "# Reattach the target column\n",
    "normalized_data = np.concatenate([normalized_features, model_df[['water_level']].to_numpy()], axis=1)\n",
    "# Preparing train and test data for LSTM\n",
    "n_past = 48  # e.g., use 24hrs past time steps to predict\n",
    "n_future = 16  # e.g., predict 4 hours ahead\n",
    "# n_features = 50\n",
    "X_train, y_train = Model.create_lstm_dataset(normalized_data, n_future, n_past)\n",
    "X_test, y_test = Model.create_lstm_dataset(normalized_data, n_future, n_past)\n",
    "\n",
    "n_features = normalized_data.shape[1]  # Assuming all columns except the target are features\n",
    "input_shape = (n_past, n_features)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Model.build_lstm_model(input_shape)\n",
    "history = Model.train_model(model, X_train, y_train, epochs=50, batch_size=32)\n",
    "predictions = Model.predict_future(model, X_test)\n",
    "\n",
    "\n",
    "X_train, y_train = Model.create_lstm_dataset(normalized_data, n_future, n_past)\n",
    "X_test, y_test = Model.create_lstm_dataset(normalized_data, n_future, n_past)\n",
    "\n",
    "# Building and training the LSTM model\n",
    "lstm_model_wo_water = Model.build_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "history = Model.train_model(lstm_model_wo_water, X_train, y_train, epochs=50)\n",
    "\n",
    "# Predicting future values\n",
    "predictions_wo_water = Model.predict_future(lstm_model_wo_water, X_test)\n",
    "\n",
    "X_train, y_train = Model.create_lstm_dataset_include_water(normalized_data, n_future, n_past)\n",
    "X_test, y_test = Model.create_lstm_dataset_include_water(normalized_data, n_future, n_past)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f588b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 1s 3ms/step\n",
      "Mean Absolute Error: 0.05919130923496448\n",
      "Mean Squared Error: 0.013959264114422965\n",
      "Root Mean Squared Error: 0.11814932972481462\n",
      "R² Score: 0.961965621953317\n",
      "MAE: 0.05919130923496448, MSE: 0.013959264114422965, RMSE: 0.11814932972481462, R²: 0.961965621953317\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae, mse, rmse, r2 = Model.evaluate_model(model, X_test, y_test)\n",
    "print(f'MAE: {mae}, MSE: {mse}, RMSE: {rmse}, R²: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e3bcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 1s 3ms/step\n",
      "Mean Absolute Error: 0.060965433321353624\n",
      "Mean Squared Error: 0.013864753132669164\n",
      "Root Mean Squared Error: 0.11774868633097\n",
      "R² Score: 0.9622231331215363\n",
      "MAE: 0.060965433321353624, MSE: 0.013864753132669164, RMSE: 0.11774868633097, R²: 0.9622231331215363\n"
     ]
    }
   ],
   "source": [
    "mae, mse, rmse, r2 = Model.evaluate_model(lstm_model_wo_water, X_test, y_test)\n",
    "print(f'MAE: {mae}, MSE: {mse}, RMSE: {rmse}, R²: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7fb0af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Autoregressive Linear Model - MAE: 0.24981182799756652, MSE: 0.14879831988206543, RMSE: 0.38574385268214634, R²: 0.5943023153739073\n",
      "Linear Regression - MAE: 0.24981182799756652, MSE: 0.14879831988206543, RMSE: 0.38574385268214634, R²: 0.5943023153739073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create dataset for Scikit-learn model\n",
    "X_train_lr, y_train_lr = Model.create_sklearn_dataset(normalized_data, n_future, n_past)\n",
    "X_test_lr, y_test_lr = Model.create_sklearn_dataset(normalized_data, n_future, n_past)\n",
    "\n",
    "# Build, train, and evaluate the linear regression model\n",
    "lr_model, mae, mse, rmse, r2 = Model.sklearn_autoregressive_linear_model(X_train_lr, y_train_lr, X_test_lr, y_test_lr)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Linear Regression - MAE: {mae}, MSE: {mse}, RMSE: {rmse}, R²: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4335fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Autoregressive Linear Model - MAE: 0.322071460074731, MSE: 0.21284586873724234, RMSE: 0.46135221765722806, R²: 0.4196770756728394\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "X_train_ar, y_train_ar = Model.create_sklearn_dataset(normalized_data, n_past, n_future)\n",
    "X_test_ar, y_test_ar = Model.create_sklearn_dataset(normalized_data, n_past, n_future)\n",
    "\n",
    "# Train and evaluate the Scikit-learn autoregressive model\n",
    "sklearn_ar_model, sklearn_ar_mae, sklearn_ar_mse, sklearn_ar_rmse, sklearn_ar_r2 = Model.sklearn_autoregressive_linear_model(X_train_ar, y_train_ar, X_test_ar, y_test_ar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922bb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
